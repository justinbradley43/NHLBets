{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_keras(df_name:str, model_name:str, num_to_test:int) -> float:\n",
    "    # read data\n",
    "    df = pd.read_csv(df_name)\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # convert data to arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # split data into the appropriate groups\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # scale X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # load the saved model\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    # read the data for the predictions to be compared to\n",
    "    real_X = pd.read_csv(df_name).drop('Outcome', axis=1)\n",
    "    real_y = pd.read_csv(df_name)['Outcome']\n",
    "\n",
    "    # loop through the real data and assess how accurate the models are\n",
    "    accurate_total = 0\n",
    "    for i in [random.randint(0, len(real_X)) for _ in range(num_to_test)]:\n",
    "        try:\n",
    "            prediction = model.predict(scaler.transform(real_X.iloc[i].values.reshape(1, -1)), verbose=0)\n",
    "            actual = real_y.iloc[i]\n",
    "            if prediction > .5 and actual == 1:\n",
    "                accurate_total += 1\n",
    "            elif prediction < .5 and actual == 0:\n",
    "                accurate_total += 1\n",
    "        except:\n",
    "            pass\n",
    "    accuracy = accurate_total / num_to_test\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_keras(\"csvs/ml_X.csv\", \"built_models/keras_ml.h5\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_keras(\"csvs/ou_X.csv\", \"built_models/keras_ou.h5\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_keras(\"csvs/pl_X.csv\", \"built_models/keras_pl.h5\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def eval_pytorch(df_name: str, model_name: str, num_to_test: int) -> float:\n",
    "    # Read data\n",
    "    df = pd.read_csv(df_name)\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Convert data to arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split data into the appropriate groups\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Scale X data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    class ANN_Model(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(ANN_Model, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 512)\n",
    "            self.fc2 = nn.Linear(512, 512)\n",
    "            self.fc3 = nn.Linear(512, 1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = ANN_Model(input_size=X_train.shape[1])\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Loop through the test data and assess accuracy\n",
    "    accurate_total = 0\n",
    "    for i in np.random.randint(0, len(X_test), num_to_test):\n",
    "        input_tensor = torch.tensor(X_test[i], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        target_tensor = torch.tensor(y_test[i], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Perform prediction\n",
    "        output_tensor = model(input_tensor)\n",
    "        predicted_label = torch.round(torch.sigmoid(output_tensor))\n",
    "        \n",
    "        # Compare predicted and actual labels\n",
    "        if predicted_label == target_tensor:\n",
    "            accurate_total += 1\n",
    "\n",
    "    accuracy = accurate_total / num_to_test\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pytorch(\"csvs/ml_X.csv\", \"built_models/torch_ml.pth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pytorch(\"csvs/ou_X.csv\", \"built_models/torch_ou.pth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pytorch(\"csvs/pl_X.csv\", \"built_models/torch_pl.pth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536 0.56 0.556 0.544 0.552\n"
     ]
    }
   ],
   "source": [
    "a = eval_keras(\"csvs/new_ml_X.csv\", \"built_models/keras_ml.h5\", 500)\n",
    "b = eval_keras(\"csvs/new_ml_X.csv\", \"built_models/keras_ml.h5\", 500)\n",
    "c = eval_keras(\"csvs/new_ml_X.csv\", \"built_models/keras_ml.h5\", 500)\n",
    "d = eval_keras(\"csvs/new_ml_X.csv\", \"built_models/keras_ml.h5\", 500)\n",
    "e = eval_keras(\"csvs/new_ml_X.csv\", \"built_models/keras_ml.h5\", 500)\n",
    "\n",
    "# b = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 1000)\n",
    "# c = eval_keras(\"csvs/new_ou_X.csv\", \"built_models/keras_ou.h5\", 500)\n",
    "# d = eval_pytorch(\"csvs/new_ou_X.csv\", \"built_models/torch_ou.pth\", 500)\n",
    "# e = eval_keras(\"csvs/new_pl_X.csv\", \"built_models/keras_pl.h5\", 500)\n",
    "# f = eval_pytorch(\"csvs/new_pl_X.csv\", \"built_models/torch_pl.pth\", 500)\n",
    "\n",
    "# print(a, b, c, d, e, f)\n",
    "print(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626 0.65 0.69 0.598 0.628\n"
     ]
    }
   ],
   "source": [
    "a = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 500)\n",
    "b = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 500)\n",
    "c = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 500)\n",
    "d = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 500)\n",
    "e = eval_pytorch(\"csvs/new_ml_X.csv\", \"built_models/torch_ml.pth\", 500)\n",
    "\n",
    "print(a, b, c, d, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
